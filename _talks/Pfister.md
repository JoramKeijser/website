---
layout: post_event
title: Matching storage and recall in spiking neural networks
date: June 17, 2015
img:
speaker: Jean-Pascal Pfister
affiliation: University of Zurich, ETH Zurich
---
Synapses are highly dynamical elements with extraordinary complexity. The up- or down-regulation of synaptic strength depends on more than 100 different interacting proteins and have effects over a wide range of time constants: from milliseconds to hours or days. This stunning complexity seriously challenges the possibility to develop a complete biophysical model of synaptic plasticity. In this talk, I will take another approach and present a normative model of long-term plasticity in the context of sequence learning. Indeed, sequence learning is a general task the brain needs to solve, but it is  unclear what type of biologically plausible learning rule is suited to learn a wide class of spatiotemporal activity patterns in a robust way. I will consider a recurrent network of stochastic spiking neurons composed of both visible and hidden neurons with synapses governed by short-tern plasticity. I will then derive a generic learning rule that is matched to the neural and synaptic dynamics by minimizing an upper bound on the Kullbackâ€“Leibler divergence from the target distribution to the model distribution. The derived learning rule is consistent with spike-timing dependent plasticity in that a presynaptic spike preceding a postsynaptic spike elicits potentiation while otherwise depression emerges. In particular, the learning can be matched to the recently proposed voltage-triplet rule. Furthermore, if a synapse is depressive, the corresponding learning rule exhibits suppressive effect (a given spike suppresses the ability of a consequent spike to induce plasticity) whereas in the absence of short-term depression, the learning rule displays the opposite effect (boosting effect). Finally, the learning rule for synapses that target hidden neurons is modulated by a global factor, which shares properties with astrocytes and gives rise to testable predictions.
